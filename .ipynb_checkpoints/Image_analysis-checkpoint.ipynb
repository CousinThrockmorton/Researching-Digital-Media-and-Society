{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d387a6-01c4-4295-8e73-54ff8a0531b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import requests\n",
    "from duckduckgo_search import DDGS\n",
    "from PIL import Image # pillows python library for image editing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71934f1c-fdc6-4c85-9953-b7de0777bb52",
   "metadata": {},
   "source": [
    "For this exercise we will play around API's a bit. API stands for Application Programming Interface. It is like a user interface but for programs, that is it lets you interact with a software service in a programatic way. It is how software talks to other software to get information. This is usually done in a JSON format \n",
    "\n",
    "In this notebook we will be using DuckDuckGo's API to search the web for images programmatically. Luckily for us DuckDuckGo is free to use and someone wrote a neat wrapper python package to interact with the API. For the documentation see https://pypi.org/project/duckduckgo-search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f17fe3-abd8-40b7-8c90-fca10f1bdf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to run the query. This is similar to how the search interface looks on through the browser\n",
    "results = DDGS().images(\n",
    "    keywords=\"butterfly\",\n",
    "    region=\"wt-wt\",\n",
    "    safesearch=\"off\",\n",
    "    size=None,\n",
    "    color=\"Monochrome\",\n",
    "    type_image=None,\n",
    "    layout=None,\n",
    "    license_image=None,\n",
    "    max_results=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0745b632-0b56-48ac-b81a-3292e983c3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded downloaded_images/image_0.jpg\n",
      "Downloaded downloaded_images/image_1.jpg\n",
      "Downloaded downloaded_images/image_2.jpg\n",
      "Downloaded downloaded_images/image_3.jpg\n",
      "Failed to download image 4: 403 Client Error: Forbidden for url: https://www.publicdomainpictures.net/pictures/120000/velka/monarch-butterfly-2-1433183647wMO.jpg\n",
      "Downloaded downloaded_images/image_5.jpg\n",
      "Downloaded downloaded_images/image_6.jpg\n",
      "Downloaded downloaded_images/image_7.jpg\n",
      "Downloaded downloaded_images/image_8.jpg\n",
      "Downloaded downloaded_images/image_9.jpg\n"
     ]
    }
   ],
   "source": [
    "# Next we need to actually download the images into the current directory.\n",
    "# Let's make a folder for the outputs\n",
    "images = \"downloaded_images\"\n",
    "\n",
    "if not os.path.exists(images):\n",
    "    os.makedirs(images)\n",
    "# Loop through the resulting images\n",
    "for idx, result in enumerate(results):\n",
    "    image_url = result['image'] # get the URL of the images\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        \n",
    "        # Define a filename \n",
    "        filename = os.path.join(images, f\"image_{idx}.jpg\")\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download image {idx}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d584c-756d-4011-b2bc-19b31cfe739e",
   "metadata": {},
   "source": [
    "Analysis\n",
    "\n",
    "Now we can analyse the images. We will try out two different methods for quantitative image analysis. \n",
    "\n",
    "First we will try to stack the images with some opacity to see what the results look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6128808-f01d-45d7-ab80-42cbe75ff6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of image files sorted by name, here we can also load a specific category of images\n",
    "image_files = sorted([f for f in os.listdir(images) if f.endswith('.jpg')])\n",
    "\n",
    "# We wil do this via a loop. Loops need a starting place so we first transform one image than we go through the whole list\n",
    "base_path = os.path.join(images, image_files[0]) # get the path of the first image\n",
    "base_image = Image.open(base_path).convert(\"RGBA\") # get the first image \n",
    "alpha_mask = Image.new(\"L\", base_image.size, int(0.2 * 255)) # create a mask to set the opacity, now it is 0.2 that is 20% \n",
    "base_image.putalpha(alpha_mask) # apply the mask to the first image\n",
    "\n",
    "width, height = base_image.size # get the size of the first image this we will use to resize the rest to this size\n",
    "\n",
    "# Create an accumulator starting with the base image\n",
    "composite = base_image.copy()\n",
    "\n",
    "# Loop over the images, note these are the same steps as above\n",
    "for image_file in image_files[1:]:\n",
    "    image_path = os.path.join(images, image_file) # get the path\n",
    "    overlay = Image.open(image_path).convert(\"RGBA\") # get the image \n",
    "    # Resize the overlay to match the base image if needed \n",
    "    if overlay.size != (width, height):\n",
    "        overlay = overlay.resize((width, height))\n",
    "    \n",
    "    overlay.putalpha(alpha_mask) # apply the mask\n",
    "    \n",
    "    # Overlay onto the current composite image\n",
    "    composite = Image.alpha_composite(composite, overlay)\n",
    "\n",
    "# Save and show the final composite image\n",
    "composite.save(\"stacked_images.png\")\n",
    "composite.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a862b8-8c5f-4fd1-a25a-55179073ea98",
   "metadata": {},
   "source": [
    "Next we can wrap all this in a function to run an experiment. Here we will study the difference in image results between Russia and the US for the seach term \"Pride\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ef1849-de49-473e-a457-e5760f84be4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded downloaded_images/image_0.jpg\n",
      "Downloaded downloaded_images/image_1.jpg\n",
      "Downloaded downloaded_images/image_2.jpg\n",
      "Downloaded downloaded_images/image_3.jpg\n",
      "Failed to download image 4: 403 Client Error: Forbidden for url: https://www.publicdomainpictures.net/pictures/120000/velka/monarch-butterfly-2-1433183647wMO.jpg\n",
      "Downloaded downloaded_images/image_5.jpg\n",
      "Downloaded downloaded_images/image_6.jpg\n",
      "Downloaded downloaded_images/image_7.jpg\n",
      "Downloaded downloaded_images/image_8.jpg\n",
      "Downloaded downloaded_images/image_9.jpg\n"
     ]
    }
   ],
   "source": [
    "def create_composite_image(keywords, region=\"wt-wt\", safesearch=\"moderate\", size=None,\n",
    "                           color=None, type_image=None, layout=None,\n",
    "                           license_image=None, max_results=10, download_dir=\"downloaded_images\",\n",
    "                           composite_filename=\"stacked_images.png\", opacity=0.2):\n",
    "\n",
    "    # Run the image search\n",
    "    results = DDGS().images(\n",
    "        keywords=keywords,\n",
    "        region=region,\n",
    "        safesearch=safesearch,\n",
    "        size=size,\n",
    "        color=color,\n",
    "        type_image=type_image,\n",
    "        layout=layout,\n",
    "        license_image=license_image,\n",
    "        max_results=max_results,\n",
    "    )\n",
    "    \n",
    "    # Create the download directory if it doesn't exist\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    \n",
    "    # Download the images\n",
    "    for idx, result in enumerate(results):\n",
    "        image_url = result['image']  # Get the URL for the image\n",
    "        try:\n",
    "            response = requests.get(image_url)\n",
    "            response.raise_for_status()  # Ensure we got a valid response\n",
    "            \n",
    "            # Define the filename\n",
    "            filename = os.path.join(download_dir, f\"image_{idx}.jpg\")\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download image {idx}: {e}\")\n",
    "    \n",
    "    # Get the list of downloaded image files (sorted by name)\n",
    "    image_files = sorted([f for f in os.listdir(download_dir) if f.endswith('.jpg')])\n",
    "    if not image_files:\n",
    "        raise ValueError(\"No images were downloaded.\")\n",
    "    \n",
    "    # Open the first image as the base and convert it to RGBA\n",
    "    base_path = os.path.join(download_dir, image_files[0])\n",
    "    base_image = Image.open(base_path).convert(\"RGBA\")\n",
    "    width, height = base_image.size\n",
    "    \n",
    "    # Create an alpha mask based on the provided opacity\n",
    "    alpha_mask = Image.new(\"L\", base_image.size, int(opacity * 255))\n",
    "    base_image.putalpha(alpha_mask)\n",
    "    \n",
    "    # Initialize the composite with the base image\n",
    "    composite = base_image.copy()\n",
    "    \n",
    "    # Loop over the remaining images and composite them one by one\n",
    "    for image_file in image_files[1:]:\n",
    "        image_path = os.path.join(download_dir, image_file)\n",
    "        overlay = Image.open(image_path).convert(\"RGBA\")\n",
    "        \n",
    "        # Resize overlay to match the base image dimensions if needed\n",
    "        if overlay.size != (width, height):\n",
    "            overlay = overlay.resize((width, height))\n",
    "        \n",
    "        # Apply the same opacity mask to the overlay\n",
    "        overlay.putalpha(Image.new(\"L\", overlay.size, int(opacity * 255)))\n",
    "        \n",
    "        # Composite the overlay image onto the current composite image\n",
    "        composite = Image.alpha_composite(composite, overlay)\n",
    "    \n",
    "    # Save the composite image and display it\n",
    "    composite.save(composite_filename)\n",
    "    composite.show()\n",
    "    \n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf21ab6-b95f-4332-9e1f-da6807ddf70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded downloaded_images_ch/image_0.jpg\n",
      "Downloaded downloaded_images_ch/image_1.jpg\n",
      "Downloaded downloaded_images_ch/image_2.jpg\n",
      "Failed to download image 3: 403 Client Error: Forbidden for url: https://www.allianceforeatingdisorders.com/wp-content/uploads/2020/06/pride-flag.jpg\n",
      "Downloaded downloaded_images_ch/image_4.jpg\n",
      "Downloaded downloaded_images_ch/image_5.jpg\n",
      "Downloaded downloaded_images_ch/image_6.jpg\n",
      "Downloaded downloaded_images_ch/image_7.jpg\n",
      "Downloaded downloaded_images_ch/image_8.jpg\n",
      "Downloaded downloaded_images_ch/image_9.jpg\n",
      "Downloaded downloaded_images_ch/image_10.jpg\n",
      "Downloaded downloaded_images_ch/image_11.jpg\n",
      "Downloaded downloaded_images_ch/image_12.jpg\n",
      "Downloaded downloaded_images_ch/image_13.jpg\n",
      "Downloaded downloaded_images_ch/image_14.jpg\n",
      "Downloaded downloaded_images_ch/image_15.jpg\n",
      "Downloaded downloaded_images_ch/image_16.jpg\n",
      "Downloaded downloaded_images_ch/image_17.jpg\n",
      "Downloaded downloaded_images_ch/image_18.jpg\n",
      "Downloaded downloaded_images_ch/image_19.jpg\n",
      "Downloaded downloaded_images_us/image_0.jpg\n",
      "Downloaded downloaded_images_us/image_1.jpg\n",
      "Downloaded downloaded_images_us/image_2.jpg\n",
      "Failed to download image 3: 403 Client Error: Forbidden for url: https://www.allianceforeatingdisorders.com/wp-content/uploads/2020/06/pride-flag.jpg\n",
      "Downloaded downloaded_images_us/image_4.jpg\n",
      "Downloaded downloaded_images_us/image_5.jpg\n",
      "Downloaded downloaded_images_us/image_6.jpg\n",
      "Downloaded downloaded_images_us/image_7.jpg\n",
      "Downloaded downloaded_images_us/image_8.jpg\n",
      "Downloaded downloaded_images_us/image_9.jpg\n",
      "Downloaded downloaded_images_us/image_10.jpg\n",
      "Downloaded downloaded_images_us/image_11.jpg\n",
      "Downloaded downloaded_images_us/image_12.jpg\n",
      "Downloaded downloaded_images_us/image_13.jpg\n",
      "Downloaded downloaded_images_us/image_14.jpg\n",
      "Downloaded downloaded_images_us/image_15.jpg\n",
      "Downloaded downloaded_images_us/image_16.jpg\n",
      "Downloaded downloaded_images_us/image_17.jpg\n",
      "Downloaded downloaded_images_us/image_18.jpg\n",
      "Downloaded downloaded_images_us/image_19.jpg\n"
     ]
    }
   ],
   "source": [
    "composite_img_ru = create_composite_image(\"pride\", region=\"ru-ru\", color=None, download_dir=\"downloaded_images_ru\", composite_filename=\"stacked_images_RU.png\", max_results=20, opacity=0.2)\n",
    "composite_img_us = create_composite_image(\"pride\", region=\"us-en\", color=None, download_dir=\"downloaded_images_us\", composite_filename=\"stacked_images_US.png\", max_results=20, opacity=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6861a-2ea6-4b5c-8ed6-9fababda35fa",
   "metadata": {},
   "source": [
    "Now we can compare the results. Some images are the same but we recieve them in different order, this results in different pictures as the order in which we stack the pictures matters for visibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce7414-a17c-448b-808d-3cda78c0b146",
   "metadata": {},
   "source": [
    "We can do maybe grouping next if we want to or something else using the data we loaded. But I think this a good start to demonstrate metaimage analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digital_media",
   "language": "python",
   "name": "digital_media"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
